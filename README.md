## üìä Springboard Data Engineering Portfolio

Welcome! I'm a data engineer trained via the [Springboard Data Engineering Bootcamp](https://www.springboard.com) with hands-on projects across Azure, SQL, Python, Airflow, and more.

I build robust, scalable data pipelines and solutions that bring order to complex data environments ‚Äî ready for production and performance.

---

üöÄ Project Timeline

The table below is auto-generated from my SQL Server progress tracker (`tblMiniProjectProgress`) via a custom Python workflow.

<!-- PROJECT_TABLE_START -->
| Project | Description | Repository Link | Last Update |
|---------|-------------|-----------------|-------------|
| Kafka Mini Project | Built a streaming fraud detection system with Apache Kafka and Python. Deployed a Kafka cluster via Docker Compose, implemented a transaction generator and fraud detector using kafka-python, and routed suspicious transactions to separate topics for real-time monitoring. Demonstrates event streaming, producers, consumers, and containerization. | [GitHub Repo](https://github.com/mtholahan/kafka-mini-project) | 09/11/2025 |
| Apache Airflow Log Analyzer Mini Project | Built Apache Airflow DAGs to automate Yahoo Finance stock data ingestion, storage, and querying, then extended with a Python log analyzer to monitor execution errors. Demonstrates orchestration, scheduling, operator use, and pipeline monitoring. | [GitHub Repo](https://github.com/mtholahan/apache-airflow-mini-project) | 08/31/2025 |
| Apache Spark Optimization Mini Project | Optimized PySpark jobs by analyzing query execution plans and rewriting transformations for efficiency. Applied techniques such as reducing shuffles, tuning partitions, selecting efficient operators, and choosing optimal data formats. Demonstrates performance tuning for large-scale Spark ETL workloads using Python and PySpark. | [GitHub Repo](https://github.com/mtholahan/apache-spark-optimization-mini-project) | 08/08/2025 |
| Apache Spark Post Sales Redesign Mini Project | Redesigned a Hadoop MapReduce post-sales reporting system using Spark. Processed automobile incident data to add make/year attributes and aggregate accidents by vehicle. Implemented RDD transformations, groupByKey, and reduceByKey to generate reports efficiently, highlighting Spark‚Äôs performance advantage over MapReduce. | [GitHub Repo](https://github.com/mtholahan/apache-spark-post-sales-redesign-mini-project) | 08/05/2025 |
| Guided Capstone Project | Build an end-to-end pipeline for high-frequency equity market data. Designed database schemas, ingested daily trade and quote records from CSV/JSON into Spark, implemented EOD batch loads with deduplication, and engineered ETL jobs to calculate trade indicators, moving averages, and bid/ask movements for market analysis. | [GitHub Repo](https://github.com/mtholahan/guided-capstone-project) | 07/24/2025 |
| Azure Synaspe Analytics Mini Project | Built a data pipeline in Azure Synapse Analytics to load product data from Azure Data Lake into a dedicated SQL pool. Implemented data flow with inserts and upserts, handling schema drift and type 1 SCD updates, and orchestrated ingestion using Synapse Studio pipelines. | [GitHub Repo](https://github.com/mtholahan/azure-synaspe-analytics-mini-project) | 07/18/2025 |
| Azure DataBricks Mini Project | Implemented a PySpark mini-project in Azure Databricks to ingest, query, and transform datasets. Built solutions using PySpark DataFrame syntax rather than SparkSQL, demonstrating data ingestion, transformations, and query patterns within notebooks submitted as part of the Springboard boot camp. | [GitHub Repo](https://github.com/mtholahan/azure-pyspark-databricks-mini-project) | 07/16/2025 |
| MySQL Python Data Pipeline Mini Project | Developed a Python and SQL data pipeline for an event ticketing system. Designed a MySQL table schema, ingested CSV sales data via Python connectors, and implemented queries to analyze ticket popularity and sales trends, showcasing ETL and database integration skills. | [GitHub Repo](https://github.com/mtholahan/mysql-python-data-pipeline-mini-project) | 07/14/2025 |
| Unguided Captsone Project | This is my unguided capstone project: exploring the impact of soundtrack genre diversity on movie popularity using TMDb & MusicBrainz. | [GitHub Repo](https://github.com/mtholahan/unguided-capstone-project) | 04/22/2025 |
| PostgreSQL Tuning Mini Project | Optimized PostgreSQL queries on a computer science publications dataset. Created tables, ingested CSVs, and wrote queries to analyze conferences, authors, and publication trends. Improved performance by designing indexes, refining join/filter logic, and evaluating execution plans with EXPLAIN, demonstrating query tuning and indexing strategies. | [GitHub Repo](https://github.com/mtholahan/postgresql-tuning-mini-project) | 03/21/2025 |
| Advanced MySQLQuery Tuning Mini Project | Analyzed EuroCup 2016 data with advanced SQL queries. Imported CSV datasets into MySQL, designed schema with match, player, and referee details, and implemented queries covering match outcomes, penalty shootouts, player stats, bookings, substitutions, and referee activity to explore tournament dynamics. | [GitHub Repo](https://github.com/mtholahan/advanced-mysqlquery-tuning-mini-project) | 03/08/2025 |
| Python OOP Mini Project | Implemented a simplified banking system in Python using OOP principles. Modeled customers, accounts, employees, and services such as loans and credit cards. Applied PEP-8 style, logging, and exception handling, with UML-based design and a command-line interface for deposits, withdrawals, and account management. | [GitHub Repo](https://github.com/mtholahan/python-oop-mini-project) | 02/13/2025 |
<!-- PROJECT_TABLE_END -->

---

### üè∑Ô∏è Tags

`#SQL` `#Azure` `#Airflow` `#Spark` `#Kafka` `#DataPipeline` `#ETL` `#DataEngineering` `#Monitoring` `#Streaming` `#Automation`

---

### üìö Bootcamp Summary

- üìÖ 30+ weeks of guided, project-based curriculum  
- ‚úèÔ∏è 10 mini-projects + 1 guided and 1 unguided capstone
- üåê Focus: cloud computing, big data, orchestration, performance optimization  
- ‚úÖ Verified by mentor checkpoints and progress metrics

---

### üõ†Ô∏è Skills & Tools

<!-- ICON_BLOCK_START -->

![Airflow](https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white) ![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white) ![Databricks](https://img.shields.io/badge/Databricks-EF3E42?style=for-the-badge&logo=databricks&logoColor=white) ![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white) ![Kafka](https://img.shields.io/badge/Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white) ![Logging](https://img.shields.io/badge/Logging-4B0082?style=for-the-badge)<br/>
![Monitoring](https://img.shields.io/badge/Monitoring-555555?style=for-the-badge&logo=prometheus&logoColor=white) ![MySQL](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white) ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white) ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white) ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white) ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)<br/>
![Spark](https://img.shields.io/badge/Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black) ![SQL](https://img.shields.io/badge/SQL-336791?style=for-the-badge&logo=postgresql&logoColor=white) ![UML](https://img.shields.io/badge/UML-000000?style=for-the-badge)

<!-- ICON_BLOCK_END -->

> Tools used in real projects: data pipelines, cloud orchestration, SQL optimization, and dashboarding.

---

### üì¨ Let‚Äôs Connect

üìß Reach me on [LinkedIn](https://www.linkedin.com/in/mark-holahan-data-devotee/)  
üß† Ask me about boot camp time tracking, SQL optimization, or orchestration frameworks!

<!-- FOOTER_START -->
*Generated automatically via Python on 09-20-2025 14:22:18*
<!-- FOOTER_END -->